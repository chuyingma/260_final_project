---
title: "mental_advanced"
author: "Chuying Ma"
date: "11/27/2017"
output: html_document
---

BST 260 Final Project
Group: Chuying Ma, Jingjing Tang, Jie Yin, Xuewei Zhang

We studied our county level data from year 2000 to 2010 using classification approaches such as Logistic Regression (Logit. Reg.), K-nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA) and Random Forest (RF) based on 16 chosen features.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

try advanced techniques for classification:
```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(pROC)
library(caret)
library(randomForest)
data_all = read_csv("data_3_expo.csv")
library(dslabs)
ds_theme_set()
```

classification:

exploratory analysis for different classes:
```{r,warning=FALSE}
data_all %>%
  ggplot(aes(menthlth)) +
  geom_histogram(fill = "darkslateblue",color = "black") + 
  ggtitle("Distribution of average numbers of days mental health not good on county level")
```

First, we divided our county level data based on average number of days mental health not good during the past 30 days (menthlth) into two categories: (1) less than or equal to 10 days mental health not good (class 0); (2) larger than 10 days but smaller than 31 days (class 1).

```{r,eval=FALSE}
mean(data_all$menthlth <= 10,na.rm = T)
mean(data_all$menthlth > 10,na.rm = T)
```


divide into 2 classes, which are "good" -- 0, "bad" -- 1
```{r,eval=FALSE}
data_all$mental_class[data_all$menthlth > 0 & data_all$menthlth <= 10] <- 0
data_all$mental_class[data_all$menthlth > 10 & data_all$menthlth <= 30] <- 1
```

divide the dataset into training and test:
```{r,eval=FALSE}

dat_class = data_all %>%
  select(-c(fips,state,county,year,heartattack,ACheartdis,stroke,asthma,menthlth))

set.seed(1)
n_test <- round(nrow(dat_class) / 10)
test_indices <- sample(1:nrow(dat_class), n_test, replace=FALSE)
test_dat <- dat_class[test_indices,]
train_dat <- dat_class[-test_indices,]
```

try logistic (try different cutoff):

```{r,,eval=FALSE}
fit <- train_dat %>% 
  glm(mental_class~., data=., family = "binomial")
test_dat_com = test_dat[complete.cases(test_dat),]
p_hat_logit <- predict(fit, newdata = test_dat_com, type="response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, 1, 0)
confusionMatrix(data = y_hat_logit, reference = test_dat_com$mental_class)
summary(fit)
```


try knn (try different k):
```{r,,eval=FALSE}
knn_fit <- knn3(mental_class~.,data = train_dat)
test_dat_com = test_dat[complete.cases(test_dat),]
f_hat <- predict(knn_fit, newdata = test_dat_com)[,2]
tab <- table(pred=round(f_hat), truth=test_dat_com$mental_class)
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
```


try random forest:

prepare train and test set:
```{r,,eval=FALSE}
data_all = read_csv("data_3_expo.csv")
```


```{r,,eval=FALSE}
data_all$mental_class[data_all$menthlth > 0 & data_all$menthlth <= 10] <- 0
data_all$mental_class[data_all$menthlth > 10 & data_all$menthlth <= 30] <- 1
```

divide the dataset into training and test:
```{r,eval=FALSE}

dat_class = data_all %>%
  select(c(income7,employed,out_of_work,homemaker,student,hlthplan,exercise,smoke,drink, genhlth_fa,genhlth_po,qlactlm,pm2.5,ozone,greenness,mental_class))

set.seed(1993)
n_test <- round(nrow(dat_class)/6)
test_indices <- sample(1:nrow(dat_class), n_test, replace=FALSE)
test_dat <- dat_class[test_indices,]
train_dat <- dat_class[-test_indices,]
```

```{r,,eval=FALSE}
write_csv(train_dat,"train.csv")
write_csv(test_dat,"test.csv")
```

try random forest for new generated test and train dataset:
```{r}
test_dat = read_csv("test.csv")
train_dat = read_csv("train.csv")
```

viewing the class in 2D via our 2 exposures of interest (ozone and greenness):
```{r,warning=FALSE}
p <- train_dat %>% 
  filter(!is.na(mental_class)) %>%
  ggplot(aes(ozone, greenness)) +
  geom_point(aes(color = factor(mental_class))) +
  ggtitle("Viewing the mental_class in 2D plot with ozone and greenness")
colors <- c("lightcoral", "cornflowerblue")
p + scale_color_manual(values=colors)
```

try CART:
```{r}
library(stringr)
library(lubridate)
library(tidyr)
library(XML)
library(tree)
fit1 <- train_dat %>%
  filter(!is.na(mental_class)) %>%
  mutate(mental_class = factor(mental_class)) %>%
  tree(mental_class ~ ., data = .)

plot(fit1)
text(fit1)

```

try Random Forest
```{r}
library(randomForest)
train_dat_com = train_dat[complete.cases(train_dat),]
train_dat_com$mental_class = as.factor(train_dat_com$mental_class)


fit2 <- randomForest(mental_class ~., data = train_dat_com, ntree=500, nodesize = 15, mtry=1)
```

```{r}
test_dat_com = test_dat[complete.cases(test_dat),]
test_dat_com$mental_class = as.factor(test_dat_com$mental_class)
pred <- predict(fit2, newdata = test_dat_com, type = "class")


tab <- table(pred, test_dat_com$mental_class)
tab
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
```

```{r,,eval=FALSE}
fit3 <- randomForest(mental_class ~., data = train_dat_com, ntree=700, nodesize = 10, mtry=1)

pred <- predict(fit3, newdata = test_dat_com, type = "class")


tab <- table(pred = pred, true = test_dat_com$mental_class)
tab
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
```

try to choose best node size:
```{r,eval=FALSE}
node_size = seq(1,20,1)
accuracy = rep(0,20)
for(i in 1:20) {
  fit = randomForest(mental_class ~., data = train_dat_com, ntree=1000, nodesize = node_size[i], mtry=1)
  pred <- predict(fit, newdata = test_dat_com, type = "class")
  tab <- table(pred = pred, true = test_dat_com$mental_class)
  accuracy[i] = confusionMatrix(tab)$overall["Accuracy"]
}
node_size[which.max(accuracy)]
```

```{r,eval=FALSE}
set.seed(1)
fit1 <- randomForest(mental_class ~., data = train_dat_com, ntree=1000, nodesize = 13, mtry=3)

pred <- predict(fit1, newdata = test_dat_com, type = "class")


tab <- table(pred = pred, true = test_dat_com$mental_class)
tab
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
```

try to choose best mtry:

```{r,eval=FALSE}
set.seed(1)
node_size = seq(1,20,1)
mtry_n = seq(1,15,1)
accuracy = c()
for(i in 1:20) {
  for (j in 1:15) {
    fit = randomForest(mental_class ~., data = train_dat_com, ntree=1000, nodesize = node_size[i], mtry=mtry_n[j])
  pred <- predict(fit, newdata = test_dat_com, type = "class")
  tab <- table(pred = pred, true = test_dat_com$mental_class)
  accuracy = c(confusionMatrix(tab)$overall["Accuracy"],accuracy)
  }
}
```


```{r}
set.seed(1)
fit2 <- randomForest(mental_class ~., data = train_dat_com, ntree=1000, nodesize = 15, mtry=5)

pred <- predict(fit2, newdata = test_dat_com, type = "class")


tab <- table(pred = pred, true = test_dat_com$mental_class)
tab
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]

pred <- predict(fit2, newdata = test_dat_com,type = "prob")


tree.prob = pred[,2]
#accuracy 0.756371 
```

In order to find the important variables in the random forest:

```{r,eval=FALSE}
library(knitr)
variable_importance <- importance(fit1) 
tmp <- data_frame(feature = rownames(variable_importance),
                  Gini = variable_importance[,1]) %>%
  arrange(desc(Gini))
```

```{r,eval=FALSE}
ds_theme_set()
tmp %>%
  ggplot(aes(x=reorder(feature, Gini), y=Gini)) +
  geom_bar(stat='identity',fill = "darkseagreen2") +
  coord_flip() + xlab("Feature") +
  theme(axis.text=element_text(size=8)) + 
  ggtitle("mean feature importances for random forest classifer")
```



try to use lda and qda for classification:
```{r}
library(MASS)
lda.fit=lda(mental_class~.,data=train_dat_com)
lda.fit
lda.pred=predict(lda.fit, test_dat_com)
lda.class=lda.pred$class 
tab <- table(pred = lda.class, true = test_dat_com$mental_class)
tab
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
#0.756371 

lda.prob = lda.pred$posterior[,1]
```

```{r}

qda.fit=qda(mental_class~.,data=train_dat_com)
qda.fit

qda.pred=predict(qda.fit, test_dat_com)

qda.class=qda.pred$class 
tab = table(qda.class,test_dat_com$mental_class)
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]

qda.prob = qda.pred$posterior[,1]

#0.7319062 
```

## Logistic Regression (2 exposure)
```{r}
glm_fit <- train_dat_com %>% 
  mutate(y = as.numeric(mental_class == 1)) %>%
  glm(y ~ income7 + employed + out_of_work + homemaker + student + hlthplan + exercise + smoke + drink + genhlth_fa + genhlth_po + qlactlm + pm2.5 + ozone + greenness, data=., family = "binomial")
```

obtain prediction using the predict function:

```{r}
p_hat_logit <- predict(glm_fit, newdata = test_dat_com, type="response")
```

obtain predictions

```{r}
y_hat_logit <- ifelse(p_hat_logit > 0.5, 1, 0)
confusionMatrix(data = y_hat_logit, reference = test_dat_com$mental_class)
#0.7528 
```

## KNN

```{r,eval=FALSE}
accuracy <- c()
for(x in 1:100){
knn_fit <- knn3(mental_class~. ,data = na.omit(train_set), k=x)
f_hat <- predict(knn_fit, newdata = na.omit(test_set))[,2]
tab <- table(pred=round(f_hat), truth=na.omit(test_set)$mental_class)
accuracy[x] <- confusionMatrix(tab)$overall["Accuracy"]
}
x <- 1:100
data.frame(x, accuracy) %>% ggplot(aes(x, accuracy))+
  geom_point(aes())+
  geom_line()+
  geom_vline(xintercept=x[which.max(accuracy)], col = "red")
```

so, k=35

```{r}
knn_fit <- knn3(mental_class~. ,data = na.omit(train_dat_com), k=35)
f_hat <- predict(knn_fit, newdata = na.omit(test_dat_com))[,2]
tab <- table(pred=round(f_hat), truth=na.omit(test_dat_com)$mental_class)
confusionMatrix(tab)$overall["Accuracy"]

#0.7415902 
```


draw the ROC curve:

```{r}


roc_ran <- roc(test_dat_com$mental_class,tree.prob)
auc(roc_ran)
#0.8106
roc_qda <- roc(test_dat_com$mental_class, qda.prob)
auc(roc_qda)
#0.7757
roc_lda = roc(test_dat_com$mental_class, lda.prob)
auc(roc_lda)
#0.79
roc_lg = roc(test_dat_com$mental_class, p_hat_logit)
auc(roc_lg)
#0.7919

roc_knn = roc(test_dat_com$mental_class, f_hat)
auc(roc_knn)
#0.7852

plot(roc_ran,col = "brown1")
lines(roc_qda, col = "blue1")
lines(roc_lda,col = "darkgoldenrod")
lines(roc_lg , col = "darkorchid")
lines(roc_knn, col = "chartreuse1")
legend(0.4,0.5,c("Random Forest","QDA","LDA","LG","KNN"),col=c("brown1","blue1","darkgoldenrod","darkorchid","chartreuse1"),lty=1)
```

##conclusions for the classification

As can be seen from the combined ROC curves and the table above, all those five techniques perform relatively similar. However, we are more willing to detect potential mental problems as more sensitive as possible. Under this consideration, larger AUC is better. So, Random Forest (RF) is slightly better than other approaches.


try to use regression tree for regression:

```{r}
library(tree)
data_all = read_csv("data_3_expo.csv")
data_tree = data_all %>%
  dplyr::select(income7,employed,out_of_work,homemaker,student,hlthplan,exercise,smoke,drink, genhlth_fa,genhlth_po,qlactlm,pm2.5,ozone,greenness,menthlth)
fit_tree <- tree(menthlth ~ ., data = data_tree)
plot(fit_tree)
text(fit_tree, cex = 0.5)
```

